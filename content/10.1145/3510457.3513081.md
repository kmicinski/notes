---
title: Counterfactual explanations for models of code
date: 2026-02-16
type: paper
bibtex: |
  @inproceedings{10.1145/3510457.3513081,
  author = {Cito, J\"{u}rgen and Dillig, Isil and Murali, Vijayaraghavan and Chandra, Satish},
  title = {Counterfactual explanations for models of code},
  year = {2022},
  isbn = {9781450392266},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3510457.3513081},
  doi = {10.1145/3510457.3513081},
  abstract = {Machine learning (ML) models play an increasingly prevalent role in many software engineering tasks. However, because most models are now powered by opaque deep neural networks, it can be difficult for developers to understand why the model came to a certain conclusion and how to act upon the model's prediction. Motivated by this problem, this paper explores counterfactual explanations for models of source code. Such counterfactual explanations constitute minimal changes to the source code under which the model "changes its mind". We integrate counterfactual explanation generation to models of source code in a real-world setting. We describe considerations that impact both the ability to find realistic and plausible counterfactual explanations, as well as the usefulness of such explanation to the developers that use the model. In a series of experiments we investigate the efficacy of our approach on three different models, each based on a BERT-like architecture operating over source code.},
  booktitle = {Proceedings of the 44th International Conference on Software Engineering: Software Engineering in Practice},
  pages = {125â€“134},
  numpages = {10},
  location = {Pittsburgh, Pennsylvania},
  series = {ICSE-SEIP '22}
  }
doi: 10.1145/3510457.3513081
pdf: 10.11453510457.3513081.pdf
---

## Summary

## Key Contributions

## Notes

