Abstracting Abstract Machines
David Van Horn âˆ—

Matthew Might

Northeastern University
dvanhorn@ccs.neu.edu

University of Utah
might@cs.utah.edu

Abstract
We describe a derivational approach to abstract interpretation that
yields novel and transparently sound static analyses when applied
to well-established abstract machines. To demonstrate the technique and support our claim, we transform the CEK machine
of Felleisen and Friedman, a lazy variant of Krivineâ€™s machine,
and the stack-inspecting CM machine of Clements and Felleisen
into abstract interpretations of themselves. The resulting analyses
bound temporal ordering of program events; predict return-flow
and stack-inspection behavior; and approximate the flow and evaluation of by-need parameters. For all of these machines, we find
that a series of well-known concrete machine refactorings, plus a
technique we call store-allocated continuations, leads to machines
that abstract into static analyses simply by bounding their stores.
We demonstrate that the technique scales up uniformly to allow
static analysis of realistic language features, including tail calls,
conditionals, side effects, exceptions, first-class continuations, and
even garbage collection.
Categories and Subject Descriptors F.3.2 [Logics and Meanings
of Programs]: Semantics of Programming Languagesâ€”Program
analysis, Operational semantics; F.4.1 [Mathematical Logic and
Formal Languages]: Mathematical Logicâ€”Lambda calculus and
related systems
General Terms Languages, Theory
Keywords abstract machines, abstract interpretation

1.

Introduction

Abstract machines such as the CEK machine and Krivineâ€™s machine are first-order state transition systems that represent the core
of a real language implementation. Semantics-based program analysis, on the other hand, is concerned with safely approximating
intensional properties of such a machine as it runs a program. It
seems natural then to want to systematically derive analyses from
machines to approximate the core of realistic run-time systems.
Our goal is to develop a technique that enables direct abstract
interpretations of abstract machines by methods for transforming
a given machine description into another that computes its finite
approximation.
âˆ— Supported by the National Science Foundation under grant 0937060 to the

Computing Research Association for the CIFellow Project.

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. To copy otherwise, to republish, to post on servers or to redistribute
to lists, requires prior specific permission and/or a fee.
ICFPâ€™10, September 27â€“29, 2010, Baltimore, Maryland, USA.
Copyright c 2010 ACM 978-1-60558-794-3/10/09. . . $10.00

We demonstrate that the technique of refactoring a machine
with store-allocated continuations allows a direct structural abstraction1 by bounding the machineâ€™s store. Thus, we are able to
convert semantic techniques used to model language features into
static analysis techniques for reasoning about the behavior of those
very same features. By abstracting well-known machines, our technique delivers static analyzers that can reason about by-need evaluation, higher-order functions, tail calls, side effects, stack structure,
exceptions and first-class continuations.
The basic idea behind store-allocated continuations is not new.
SML/NJ has allocated continuations in the heap for well over a
decade [28]. At first glance, modeling the program stack in an abstract machine with store-allocated continuations would not seem
to provide any real benefit. Indeed, for the purpose of defining the
meaning of a program, there is no benefit, because the meaning
of the program does not depend on the stack-implementation strategy. Yet, a closer inspection finds that store-allocating continuations eliminate recursion from the definition of the state-space of
the machine. With no recursive structure in the state-space, an abstract machine becomes eligible for conversion into an abstract interpreter through a simple structural abstraction.
To demonstrate the applicability of the approach, we derive
abstract interpreters of:
â€¢ a call-by-value Î»-calculus with state and control based on the

CESK machine of Felleisen and Friedman [13],
â€¢ a call-by-need Î»-calculus based on a tail-recursive, lazy vari-

ant of Krivineâ€™s machine derived by Ager, Danvy and Midtgaard [1], and
â€¢ a call-by-value Î»-calculus with stack inspection based on the

CM machine of Clements and Felleisen [3];
and use abstract garbage collection to improve precision [25].
Overview
In Section 2, we begin with the CEK machine and attempt a structural abstract interpretation, but find ourselves blocked by two recursive structures in the machine: environments and continuations.
We make three refactorings to:
1. store-allocate bindings,
2. store-allocate continuations, and
3. time-stamp machine states;
resulting in the CESK, CESK? , and time-stamped CESK? machines, respectively. The time-stamps encode the history (context)
of the machineâ€™s execution and facilitate context-sensitive abstractions. We then demonstrate that the time-stamped machine abstracts directly into a parameterized, sound and computable static
analysis.
1 A structural abstraction distributes component-, point-, and member-wise.

In Section 3, we replay this process (slightly abbreviated) with
a lazy variant of Krivineâ€™s machine to arrive at a static analysis of
by-need programs.
In Section 4, we incorporate conditionals, side effects, exceptions, first-class continuations, and garbage collection.
In Section 6, we abstract the CM (continuation-marks) machine
to produce an abstract interpretation of stack inspection.
In Section 7, we widen the abstract interpretations with a singlethreaded â€œglobalâ€ store to accelerate convergence. For some of our
analyzers, this widening results in polynomial-time algorithms and
connects them back to known analyses.

2.

From CEK to the abstract CESK?

In this section, we start with a traditional machine for a programming language based on the call-by-value Î»-calculus, and gradually derive an abstract interpretation of this machine. The outline
followed in this section covers the basic steps for systematically
deriving abstract interpreters that we follow throughout the rest of
the paper.
To begin, consider the following language of expressions:2
e âˆˆ Exp ::= x | (ee) | (Î»x.e)
x âˆˆ Var
a set of identifiers.
A standard machine for evaluating this language is the CEK machine of Felleisen and Friedman [12], and it is from this machine
we derive the abstract semanticsâ€”a computable approximation of
the machineâ€™s behavior. Most of the steps in this derivation correspond to well-known machine transformations and real-world implementation techniquesâ€”and most of these steps are concerned
only with the concrete machine; a very simple abstraction is employed only at the very end.
The remainder of this section is outlined as follows: we present
the CEK machine, to which we add a store, and use it to allocate variable bindings. This machine is just the CESK machine of
Felleisen and Friedman [13]. From here, we further exploit the store
to allocate continuations, which corresponds to a well-known implementation technique used in functional language compilers [28].
We then abstract only the store to obtain a framework for the sound,
computable analysis of programs.

Ï‚ 7âˆ’â†’CEK Ï‚ 0
hx, Ï, Îºi
h(e0 e1 ), Ï, Îºi
hv, Ï, ar(e, Ï0 , Îº)i
hv, Ï, fn((Î»x.e), Ï0 , Îº)i

hv, Ï0 , Îºi where Ï(x) = (v, Ï0 )
he0 , Ï, ar(e1 , Ï, Îº)i
he, Ï0 , fn(v, Ï, Îº)i
he, Ï0 [x 7â†’ (v, Ï)], Îºi

Figure 1. The CEK machine.
An expression is either a value or uniquely decomposable into an
evaluation context and redex. The standard reduction machine is:
E[e] 7âˆ’â†’Î²v E[e0 ], if e Î²v e0 .
However, this machine does not shed much light on a realistic
implementation. At each step, the machine traverses the entire
source of the program looking for a redex. When found, the redex
is reduced and the contractum is plugged back in the hole, then the
process is repeated.
Abstract machines such as the CEK machine, which are derivable from standard reduction machines, offer an extensionally
equivalent but more realistic model of evaluation that is amenable
to efficient implementation. The CEK is environment-based; it uses
environments and closures to model substitution. It represents evaluation contexts as continuations, an inductive data structure that
models contexts in an inside-out manner. The key idea of machines
such as the CEK is that the whole program need not be traversed
to find the next redex, consequently the machine integrates the process of plugging a contractum into a context and finding the next
redex.
States of the CEK machine [12] consist of a control string (an
expression), an environment that closes the control string, and a
continuation:
Ï‚âˆˆÎ£
= Exp Ã— Env Ã— Kont
v âˆˆ Val ::= (Î»x.e)
Ï âˆˆ Env = Var â†’fin Val Ã— Env
Îº âˆˆ Kont ::= mt | ar(e, Ï, Îº) | fn(v, Ï, Îº).

A standard approach to evaluating programs is to rely on a CurryFeys-style Standardization Theorem, which says roughly: if an
expression e reduces to e0 in, e.g., the call-by-value Î»-calculus,
then e reduces to e0 in a canonical manner. This canonical manner
thus determines a state machine for evaluating programs: a standard
reduction machine.
To define such a machine for our language, we define a grammar
of evaluation contexts and notions of reduction (e.g., Î²v ). An evaluation context is an expression with a â€œholeâ€ in it. For left-to-right
evaluation order, we define evaluation contexts E as:

States are identified up to consistent renaming of bound variables.
Environments are finite maps from variables to closures. Environment extension is written Ï[x 7â†’ (v, Ï0 )].
Evaluation contexts E are represented (inside-out) by continuations as follows: [ ] is represented by mt; E[([ ]e)] is represented
by ar(e0 , Ï, Îº) where Ï closes e0 to represent e and Îº represents
E; E[(v[ ])] is represented by fn(v 0 , Ï, Îº) where Ï closes v 0 to
represent v and Îº represents E.
The transition function for the CEK machine is defined in Figure 1 (we follow the textbook treatment of the CEK machine [11,
page 102]). The initial machine state for a closed expression e is
given by the inj function:

E ::= [ ] | (Ee) | (vE).

inj CEK (e) = he, âˆ…, mti.

2 Fine print on syntax: As is often the case in program analysis where se-

Typically, an evaluation function is defined as a partial function
from closed expressions to answers:

2.1

The CEK machine

mantic values are approximated using syntactic phrases of the program under analysis, we would like to be able to distinguish different syntactic occurrences of otherwise identical expressions within a program. Informally,
this means we want to track the source location of expressions. Formally,
this is achieved by labeling expressions and assuming all labels within a
program are distinct:
e âˆˆ Exp ::= x` | (ee)` | (Î»x.e)`
` âˆˆ Lab
an infinite set of labels.
However, we judiciously omit labels whenever they are irrelevant and doing
so improves the clarity of the presentation. Consequently, they appear only
in Sections 2.7 and 7, which are concerned with k-CFA.

eval 0CEK (e) = (v, Ï) if inj (e) 7âˆ’â†’
â†’CEK hv, Ï, mti.
This gives an extensional view of the machine, which is useful, e.g.,
to prove correctness with respect to a canonical evaluation function
such as one defined by standard reduction or compositional valuation. However for the purposes of program analysis, we are concerned more with the intensional aspects of the machine. As such,
we define the meaning of a program as the (possibly infinite) set of
reachable machine states:
eval CEK (e) = {Ï‚ | inj (e) 7âˆ’â†’
â†’CEK Ï‚}.

Deciding membership in the set of reachable machine states
is not possible due to the halting problem. The goal of abstract
interpretation, then, is to construct a function, aval CEK
[ , that is a
sound and computable approximation to the eval CEK function.
We can do this by constructing a machine that is similar in structure to the CEK machine: it is defined by an abstract state transition
relation (7âˆ’â†’CEK
[ ) âŠ† Î£Ì‚ Ã— Î£Ì‚, which operates over abstract states,
Î£Ì‚, which approximate the states of the CEK machine, and an abstraction map Î± : Î£ â†’ Î£Ì‚ that maps concrete machine states into
abstract machine states.
The abstract evaluation function is then defined as:

Ï‚ 7âˆ’â†’CESK Ï‚ 0
hx, Ï, Ïƒ, Îºi
hv, Ï0 , Ïƒ, Îºi where Ïƒ(Ï(x)) = (v, Ï0 )
h(e0 e1 ), Ï, Ïƒ, Îºi
he0 , Ï, Ïƒ, ar(e1 , Ï, Îº)i
hv, Ï, Ïƒ, ar(e, Ï0 , Îº)i
he, Ï0 , Ïƒ, fn(v, Ï, Îº)i
0
0
he, Ï [x 7â†’ a], Ïƒ[a 7â†’ (v, Ï)], Îºi
hv, Ï, Ïƒ, fn((Î»x.e), Ï , Îº)i
where a âˆˆ
/ dom(Ïƒ)
Figure 2. The CESK machine.

aval CEK
Ï‚ | Î±(inj (e)) 7âˆ’â†’
â†’CEK
[ (e) = {Ë†
[ Ï‚Ë†}.

The state space for the CESK machine is defined as follows:
Ï‚âˆˆÎ£
= Exp Ã— Env Ã— Store Ã— Kont
Ï âˆˆ Env
= Var â†’fin Addr
Ïƒ âˆˆ Store
= Addr â†’fin Storable
s âˆˆ Storable = Val Ã— Env
a, b, c âˆˆ Addr
an infinite set.

1. We achieve decidability by constructing the approximation in
such a way that the state-space of the abstracted machine is
finite, which guarantees that for any closed expression e, the
set aval (e) is finite.
2. We achieve soundness by demonstrating the abstracted machine transitions preserve the abstraction map, so that if Ï‚ 7âˆ’â†’
Ï‚ 0 and Î±(Ï‚) v Ï‚Ë†, then there exists an abstract state Ï‚Ë†0 such that
Ï‚Ë† 7âˆ’â†’ Ï‚Ë†0 and Î±(Ï‚ 0 ) v Ï‚Ë†0 .
A first attempt at abstract interpretation: A simple approach
to abstracting the machineâ€™s state space is to apply a structural
abstract interpretation, which lifts abstraction point-wise, elementwise, component-wise and member-wise across the structure of a
machine state (i.e., expressions, environments, and continuations).
The problem with the structural abstraction approach for the
CEK machine is that both environments and continuations are
recursive structures. As a result, the map Î± yields objects in an
abstract state-space with recursive structure, implying the space
is infinite. It is possible to perform abstract interpretation over an
infinite state-space, but it requires a widening operator. A widening
operator accelerates the ascent up the lattice of approximation and
must guarantee convergence. It is difficult to imagine a widening
operator, other than the one that jumps immediately to the top of
the lattice, for these semantics.
Focusing on recursive structure as the source of the problem, a
reasonable course of action is to add a level of indirection to the
recursionâ€”to force recursive structure to pass through explicitly
allocated addresses. In doing so, we will unhinge recursion in
a programâ€™s data structures and its control-flow from recursive
structure in the state-space.
We turn our attention next to the CESK machine [10, 13], since
the CESK machine eliminates recursion from one of the structures
in the CEK machine: environments. In the subsequent section (Section 2.3), we will develop a CESK machine with a pointer refinement (CESK? ) that eliminates the other source of recursive structure: continuations. At that point, the machine structurally abstracts
via a single point of approximation: the store.
2.2

The CESK machine

The states of the CESK machine extend those of the CEK machine
to include a store, which provides a level of indirection for variable
bindings to pass through. The store is a finite map from addresses
to storable values and environments are changed to map variables
to addresses. When a variableâ€™s value is looked-up by the machine,
it is now accomplished by using the environment to look up the
variableâ€™s address, which is then used to look up the value. To
bind a variable to a value, a fresh location in the store is allocated
and mapped to the value; the environment is extended to map the
variable to that address.

States are identified up to consistent renaming of bound variables
and addresses. The transition function for the CESK machine is
defined in Figure 2 (we follow the textbook treatment of the CESK
machine [11, page 166]).
The initial state for a closed expression is given by the inj function, which combines the expression with the empty environment,
store, and continuation:
inj CESK (e) = he, âˆ…, âˆ…, mti.
The eval CESK evaluation function is defined following the template of the CEK evaluation given in Section 2.1:
eval CESK (e) = {Ï‚ | inj (e) 7âˆ’â†’
â†’CESK Ï‚}.
Observe that for any closed expression, the CEK and CESK machines operate in lock-step: each machine transitions, by the corresponding rule, if and only if the other machine transitions.
Lemma 1 (Felleisen, [10]). eval CESK (e) â‰ƒ eval CEK (e).
A second attempt at abstract interpretation: With the CESK machine, half the problem with the attempted naÄ±Ìˆve abstract interpretation is solved: environments and closures are no longer mutually
recursive. Unfortunately, continuations still have recursive structure. We could crudely abstract a continuation into a set of frames,
losing all sense of order, but this would lead to a static analysis lacking faculties to reason about return-flow: every call would appear
to return to every other call. A better solution is to refactor continuations as we did environments, redirecting the recursive structure
through the store. In the next section, we explore a CESK machine
with a pointer refinement for continuations.
2.3

The CESK? machine

To untie the recursive structure associated with continuations, we
shift to store-allocated continuations. The Kont component of the
machine is replaced by a pointer to a continuation allocated in
the store. We term the resulting machine the CESK? (control,
environment, store, continuation pointer) machine. Notice the store
now maps to denotable values and continuations:
Ï‚âˆˆÎ£
= Exp Ã— Env Ã— Store Ã— Addr
s âˆˆ Storable = Val Ã— Env + Kont
Îº âˆˆ Kont
::= mt | ar(e, Ï, a) | fn(v, Ï, a).
The revised machine is defined in Figure 3 and the initial machine state is defined as:
inj CESK ? (e) = he, âˆ…, [a0 7â†’ mt], a0 i.

Ï‚ 7âˆ’â†’CESK ? Ï‚ 0 , where Îº = Ïƒ(a), b âˆˆ
/ dom(Ïƒ)
hx, Ï, Ïƒ, ai
h(e0 e1 ), Ï, Ïƒ, ai
hv, Ï, Ïƒ, ai
if Îº = ar(e, Ï0 , c)
if Îº = fn((Î»x.e), Ï0 , c)

hv, Ï0 , Ïƒ, ai where (v, Ï0 ) = Ïƒ(Ï(x))
he0 , Ï, Ïƒ[b 7â†’ ar(e1 , Ï, a)], bi
he, Ï0 , Ïƒ[b 7â†’ fn(v, Ï, c)], bi
he, Ï0 [x 7â†’ b], Ïƒ[b 7â†’ (v, Ï)], ci

Ï‚ 7âˆ’â†’CESK ?t Ï‚ 0 , where Îº = Ïƒ(a), b = alloc(Ï‚), u = tick(t)
hx, Ï, Ïƒ, a, ti
hv, Ï0 , Ïƒ, a, ui where (v, Ï0 ) = Ïƒ(Ï(x))
h(e0 e1 ), Ï, Ïƒ, a, ti
he0 , Ï, Ïƒ[b 7â†’ ar(e1 , Ï, a)], b, ui
hv, Ï, Ïƒ, a, ti
if Îº = ar(e, Ï, c)
he, Ï, Ïƒ[b 7â†’ fn(v, Ï, c)], b, ui
if Îº = fn((Î»x.e), Ï0 , c)
he, Ï0 [x 7â†’ b], Ïƒ[b 7â†’ (v, Ï)], c, ui

Figure 3. The CESK? machine.

Figure 4. The time-stamped CESK? machine.

The evaluation function (not shown) is defined along the same
lines as those for the CEK (Section 2.1) and CESK (Section 2.2)
machines. Like the CESK machine, it is easy to relate the CESK?
machine to its predecessor; from corresponding initial configurations, these machines operate in lock-step:

The tick function returns the next time; the alloc function allocates
a fresh address for a binding or continuation. We require of tick
and alloc that for all t and Ï‚, t < tick(t) and alloc(Ï‚) âˆˆ
/ Ïƒ where
Ï‚ = h , , Ïƒ, , i.
The time-stamped CESK? machine is defined in Figure 4. Note
that occurrences of Ï‚ on the right-hand side of this definition are
implicitly bound to the state occurring on the left-hand side. The
initial machine state is defined as:

Lemma 2. eval CESK ? (e) â‰ƒ eval CESK (e).
Addresses, abstraction and allocation: The CESK? machine, as
defined in Figure 3, nondeterministically chooses addresses when
it allocates a location in the store, but because machines are identified up to consistent renaming of addresses, the transition system
remains deterministic.
Looking ahead, an easy way to bound the state-space of this
machine is to bound the set of addresses.3 But once the store is
finite, locations may need to be reused and when multiple values
are to reside in the same location; the store will have to soundly
approximate this by joining the values.
In our concrete machine, all that matters about an allocation
strategy is that it picks an unused address. In the abstracted machine however, the strategy may have to re-use previously allocated addresses. The abstract allocation strategy is therefore crucial to the design of the analysisâ€”it indicates when finite resources
should be doled out and decides when information should deliberately be lost in the service of computing within bounded resources.
In essence, the allocation strategy is the heart of an analysis (allocation strategies corresponding to well-known analyses are given
in Section 2.7.)
For this reason, concrete allocation deserves a bit more attention in the machine. An old idea in program analysis is that dynamically allocated storage can be represented by the state of the
computation at allocation time [18, 22, Section 1.2.2]. That is, allocation strategies can be based on a (representation) of the machine
history. These representations are often called time-stamps.
A common choice for a time-stamp, popularized by Shivers [29], is to represent the history of the computation as contours,
finite strings encoding the calling context. We present a concrete
machine that uses general time-stamp approach and is parameterized by a choice of tick and alloc functions. We then instantiate
tick and alloc to obtain an abstract machine for computing a kCFA-style analysis using the contour approach.
2.4

The time-stamped CESK? machine

inj CESKt? (e) = he, âˆ…, [a0 7â†’ mt], a0 , t0 i.
Satisfying definitions for the parameters are:
a 0 = t0 = 0

Time = Addr = Z
tickh , , , , ti = t + 1 alloch , , , , ti = t.

Under these definitions, the time-stamped CESK? machine operates in lock-step with the CESK? machine, and therefore with the
CESK and CEK machines as well.
Lemma 3. eval CESKt? (e) â‰ƒ eval CESK ? (e).
The time-stamped CESK? machine forms the basis of our abstracted machine in the following section.
2.5

The abstract time-stamped CESK? machine

As alluded to earlier, with the time-stamped CESK? machine, we
now have a machine ready for direct abstract interpretation via a
single point of approximation: the store. Our goal is a machine
that resembles the time-stamped CESK? machine, but operates
over a finite state-space and it is allowed to be nondeterministic.
Once the state-space is finite, the transitive closure of the transition
relation becomes computable, and this transitive closure constitutes
a static analysis. Buried in a path through the transitive closure
is a (possibly infinite) traversal that corresponds to the concrete
execution of the program.
The abstracted variant of the time-stamped CESK? machine
comes from bounding the address space of the store and the number
of times available. By bounding these sets, the state-space becomes
finite,4 but for the purposes of soundness, an entry in the store may
be forced to hold several values simultaneously:
[ = Addr â†’fin P (Storable).
ÏƒÌ‚ âˆˆ Store

3 A finite number of addresses leads to a finite number of environments,

Hence, stores now map an address to a set of storable values rather
than a single value. These collections of values model approximation in the analysis. If a location in the store is re-used, the new
value is joined with the current set of values. When a location is
dereferenced, the analysis must consider any of the values in the
set as a result of the dereference.
The abstract time-stamped CESK? machine is defined in Figure 5. The (non-deterministic) abstract transition relation changes
little compared with the concrete machine. We only have to modify
it to account for the possibility that multiple storable values (which

which leads to a finite number of closures and continuations, which in turn,
leads to a finite number of stores, and finally, a finite number of states.

4 Syntactic sets like Exp are infinite, but finite for any given program.

The machine states of the time-stamped CESK? machine include a
time component, which is intentionally left unspecified:
t, u âˆˆ Time
Ï‚ âˆˆ Î£ = Exp Ã— Env Ã— Store Ã— Addr Ã— Time.
The machine is parameterized by the functions:
tick : Î£ â†’ Time

alloc : Î£ â†’ Addr .

0
d Îº)
[ Ï‚ , Îº), u = tick(t,
Ï‚Ë† 7âˆ’â†’CESK
\? Ï‚Ë† , where Îº âˆˆ ÏƒÌ‚(a), b = alloc(Ë†

Î±(e, Ï, Ïƒ, a, t) = (e, Î±(Ï), Î±(Ïƒ), Î±(a), Î±(t))

[states]

t

hx, Ï, ÏƒÌ‚, a, ti
hv, Ï0 , ÏƒÌ‚, a, ui where (v, Ï0 ) âˆˆ ÏƒÌ‚(Ï(x))
h(e0 e1 ), Ï, ÏƒÌ‚, a, ti
he0 , Ï, ÏƒÌ‚ t [b 7â†’ ar(e1 , Ï, a)], b, ui
hv, Ï, ÏƒÌ‚, a, ti
if Îº = ar(e, Ï0 , c)
he, Ï0 , ÏƒÌ‚ t [b 7â†’ fn(v, Ï, c)], b, ui
if Îº = fn((Î»x.e), Ï0 , c)
he, Ï0 [x 7â†’ b], ÏƒÌ‚ t [b 7â†’ (v, Ï)], c, ui

Î±(Ï) = Î»x.Î±(Ï(x))
G
Î±(Ïƒ) = Î»aÌ‚.
{Î±(Ïƒ(a))}

[environments]
[stores]

Î±(a)=aÌ‚

Î±((Î»x.e), Ï) = ((Î»x.e), Î±(Ï))
Î±(mt) = mt

[closures]
[continuations]

Î±(ar(e, Ï, a)) = ar(e, Î±(Ï), Î±(a))
Figure 5. The abstract time-stamped CESK? machine.
includes continuations) may reside together in the store, which we
handle by letting the machine non-deterministically choose a particular value from the set at a given store location.
The analysis is parameterized by abstract variants of the functions that parameterized the concrete version:
d : Î£Ì‚ Ã— Kont â†’ Time,
tick

[ : Î£Ì‚ Ã— Kont â†’ Addr .
alloc

In the concrete, these parameters determine allocation and stack
behavior. In the abstract, they are the arbiters of precision: they
determine when an address gets re-allocated, how many addresses
get allocated, and which values have to share addresses.
Recall that in the concrete semantics, these functions consume
statesâ€”not states and continuations as they do here. This is because
in the concrete, a state alone suffices since the state determines the
continuation. But in the abstract, a continuation pointer within a
state may denote a multitude of continuations; however the transition relation is defined with respect to the choice of a particular
one. We thus pair states with continuations to encode the choice.
The abstract semantics computes the set of reachable states:
Ï‚ | he, âˆ…, [a0 7â†’ mt], a0 , t0 i 7âˆ’â†’
â†’CESK
aval CESK
\? Ï‚Ë†}.
\? (e) = {Ë†
t

t

2.6

Soundness and computability

The finiteness of the abstract state-space ensures decidability.
Theorem 1 (Decidability of the Abstract CESK? Machine).
Ï‚Ë† âˆˆ aval CESK
\? (e) is decidable.
t

Proof. The state-space of the machine is non-recursive with finite
sets at the leaves on the assumption that addresses are finite. Hence
reachability is decidable since the abstract state-space is finite.
We have endeavored to evolve the abstract machine gradually so
that its fidelity in soundly simulating the original CEK machine is
both intuitive and obvious. But to formally establish soundness of
the abstract time-stamped CESK? machine, we use an abstraction
function, defined in Figure 6, from the state-space of the concrete
time-stamped machine into the abstracted state-space.
The abstraction map over times and addresses is defined so
d are sound simulations of the
[ and tick
that the parameters alloc
parameters alloc and tick, respectively. We also define the partial
order (v) on the abstract state-space as the natural point-wise,
element-wise, component-wise and member-wise lifting, wherein
the partial orders on the sets Exp and Addr are flat. Then, we
can prove that abstract machineâ€™s transition relation simulates the
concrete machineâ€™s transition relation.
Theorem 2 (Soundness of the Abstract CESK? Machine).
If Ï‚ 7âˆ’â†’CEK Ï‚ 0 and Î±(Ï‚) v Ï‚Ë†, then there exists an abstract state
0
0
0
Ï‚Ë†0 , such that Ï‚Ë† 7âˆ’â†’CESK
\ ? Ï‚Ë† and Î±(Ï‚ ) v Ï‚Ë† .
t

Proof. By Lemmas 1, 2, and 3, it suffices to prove soundness with
respect to 7âˆ’â†’CESK ?t . Assume Ï‚ 7âˆ’â†’CESK ?t Ï‚ 0 and Î±(Ï‚) v Ï‚Ë†.

Î±(fn(v, Ï, a)) = fn(v, Î±(Ï), Î±(a)),
Figure 6. The abstraction map, Î± : Î£CESK ?t â†’ Î£Ì‚CESK
\? .
t

Because Ï‚ transitioned, exactly one of the rules from the definition
of (7âˆ’â†’CESK ?t ) applies. We split by cases on these rules. The rule
for the second case is deterministic and follows by calculation.
For the the remaining (nondeterministic) cases, we must show
an abstract state exists such that the simulation is preserved. By
examining the rules for these cases, we see that all three hinge on
the abstract store in Ï‚Ë† soundly approximating the concrete store in
Ï‚, which follows from the assumption that Î±(Ï‚) v Ï‚Ë†.
2.7

A k-CFA-like abstract CESK? machine

In this section, we instantiate the time-stamped CESK? machine
to obtain a contour-based machine; this instantiation forms the
basis of a context-sensitive abstract interpreter with polyvariance
like that found in k-CFA [29]. In preparation for abstraction, we
instantiate the time-stamped machine using labeled call strings.
Inside times, we use contours (Contour ), which are finite
strings of call site labels that describe the current context:
Î´ âˆˆ Contour ::=  | `Î´.
The labeled CESK machine transition relation must appropriately instantiate the parameters tick and alloc to augment the timestamp on function call.
Next, we switch to abstract stores and bound the address space
by truncating call string contours to length at most k (for k-CFA):
\ k iff Î´ âˆˆ Contour and |Î´| â‰¤ k.
Î´ âˆˆ Contour
Combining these changes, we arrive at the instantiations for the
concrete and abstract machines given in Figure 7, where the value
bÎ´ck is the leftmost k labels of contour Î´.
Comparison to k-CFA: We say â€œk-CFA-likeâ€ rather than â€œkCFAâ€ because there are distinctions between the machine just described and k-CFA:
1. k-CFA focuses on â€œwhat flows whereâ€; the ordering between
states in the abstract transition graph produced by our machine
produces â€œwhat flows where and when.â€
2. Standard presentations of k-CFA implicitly inline a global approximation of the store into the algorithm [29]; ours uses one
store per state to increase precision at the cost of complexity. In
terms of our framework, the lattice through which classical k[
CFA ascends is P (Exp Ã— Env
â€œ Ã— Addr ) Ã— Store, whereas our
â€
[ Ã— Addr .
analysis ascends the lattice P Exp Ã— Env Ã— Store
We can explicitly inline the store to achieve the same complexity, as shown in Section 7.
3. On function call, k-CFA merges argument values together with
previous instances of those arguments from the same context;
our â€œminimalistâ€ evolution of the abstract machine takes a

Ï‚ 7âˆ’â†’LK Ï‚ 0

Time = (Lab + â€¢) Ã— Contour
Addr = (Lab + Var ) Ã— Contour
hx, Ï, Ïƒ, Îºi
if Ïƒ(Ï(x)) = d(e, Ï0 )
if Ïƒ(Ï(x)) = c(v, Ï0 )
h(e0 e1 ), Ï, Ïƒ, Îºi

t0 = (â€¢, )
tickhx, , , , ti = t
tickh(e0 e1 )` , , , , ( , Î´)i = (`, Î´)
(
(`, Î´),
tickhv, , Ïƒ, a, (`, Î´)i =
(â€¢, `Î´),

if Ïƒ(a) = ar( , , )
if Ïƒ(a) = fn( , , )

hv, Ï, Ïƒ, c1 (a, Îº)i
h(Î»x.e), Ï, Ïƒ, c2 (a, Îº)i

alloc(h(e`0 e1 ), , , , ( , Î´)i) = (`, Î´)

he, Ï0 , Ïƒ, c1 (Ï(x), Îº)i
hv, Ï0 , Ïƒ, Îºi
he0 , Ï, Ïƒ[a 7â†’ d(e1 , Ï)], c2 (a, Îº)i
where a âˆˆ
/ dom(Ïƒ)
hv, Ï, Ïƒ[a 7â†’ c(v, Ï)], Îºi
he, Ï[x 7â†’ a], Ïƒ, Îºi

Figure 8. The LK machine.

alloc(hv, , Ïƒ, a, ( , Î´)i) = (`, Î´) if Ïƒ(a) = ar(e` , , )
alloc(hv, , Ïƒ, a, ( , Î´)i) = (x, Î´) if Ïƒ(a) = fn((Î»x.e), , )

d Ï‚ , Îº)
[ Ï‚ , Îº), u = tick(Ë†
Ë†0 , where Îº âˆˆ ÏƒÌ‚(a), b = alloc(Ë†
Ï‚Ë† 7âˆ’â†’LK
? Ï‚
[
t

d
, , , ti, Îº) = t
tick(hx,
`
d
tick(h(e
0 e1 ) , , , , ( , Î´)i, Îº) = (`, Î´)
(
(`, Î´),
d
, ÏƒÌ‚, a, (`, Î´)i, Îº) =
tick(hv,
(â€¢, b`Î´ck ),

if Îº = ar( , , )
if Îº = fn( , , )

`
[
alloc(h(e
0 e1 ), , , , ( , Î´)i, Îº) = (`, Î´)

hx, Ï, ÏƒÌ‚, a, ti
if ÏƒÌ‚(Ï(x)) 3 d(e, Ï0 )
hx, Ï, ÏƒÌ‚, a, ti
if ÏƒÌ‚(Ï(x)) 3 c(v, Ï0 )
h(e0 e1 ), Ï, ÏƒÌ‚, a, ti

[
alloc(hv,
, ÏƒÌ‚, a, ( , Î´)i, Îº) = (`, Î´) if Îº = ar(e` , , )
[
alloc(hv,
, ÏƒÌ‚, a, ( , Î´)i, Îº) = (x, Î´) if Îº = fn((Î»x.e), , )
Figure 7. Instantiation for k-CFA machine.
higher-precision approach: it forks the machine for each argument value, rather than merging them immediately.
4. k-CFA does not recover explicit information about stack structure; our machine contains an explicit model of the stack for
every machine state.

3.

Analyzing by-need with Krivineâ€™s machine

Even though the abstract machines of the prior section have advantages over traditional CFAs, the approach we took (store-allocated
continuations) yields more novel results when applied in a different
context: a lazy variant of Krivineâ€™s machine. That is, we can construct an abstract interpreter that both analyzes and exploits laziness. Specifically, we present an abstract analog to a lazy and properly tail-recursive variant of Krivineâ€™s machine [19, 20] derived by
Ager, Danvy, and Midtgaard [1]. The derivation from Ager et al.â€™s
machine to the abstract interpreter follows the same outline as that
of Section 2: we apply a pointer refinement by store-allocating continuations and carry out approximation by bounding the store.
The by-need variant of Krivineâ€™s machine considered here uses
the common implementation technique of store-allocating thunks
and forced values. When an application is evaluated, a thunk is
created that will compute the value of the argument when forced.
When a variable occurrence is evaluated, if it is bound to a thunk,
the thunk is forced (evaluated) and the store is updated to the result.
Otherwise if a variable occurrence is evaluated and bound to a
forced value, that value is returned.
Storable values include delayed computations (thunks) d(e, Ï),
and computed values c(v, Ï), which are just tagged closures. There
are two continuation constructors: c1 (a, Îº) is induced by a variable
occurrence whose binding has not yet been forced to a value.
The address a is where we want to write the given value when
this continuation is invoked. The other: c2 (a, Îº) is induced by an

hv, Ï, ÏƒÌ‚, a, ti
if Îº = c1 (a0 , c)
h(Î»x.e), Ï, ÏƒÌ‚, a, ti
if Îº = c2 (a0 , c)

he, Ï0 , ÏƒÌ‚ t [b 7â†’ c1 (Ï(x), a)], b, ui
hv, Ï0 , ÏƒÌ‚, a, ui
he0 , Ï, ÏƒÌ‚ 0 , b, ui
[ Ï‚ , Îº),
where c = alloc(Ë†
ÏƒÌ‚ 0 = ÏƒÌ‚ t [c 7â†’ d(e1 , Ï), b 7â†’ c2 (c, a)]
hv, Ï0 , ÏƒÌ‚ t [a0 7â†’ c(v, Ï)], c, ui
he, Ï0 [x 7â†’ a0 ], ÏƒÌ‚, c, ui

Figure 9. The abstract LK? machine.
application expression, which forces the operator expression to a
value. The address a is the address of the argument.
The concrete state-space is defined as follows and the transition
relation is defined in Figure 8:
Ï‚âˆˆÎ£
= Exp Ã— Env Ã— Store Ã— Kont
s âˆˆ Storable ::= d(e, Ï) | c(v, Ï)
Îº âˆˆ Kont
::= mt | c1 (a, Îº) | c2 (a, Îº)
When the control component is a variable, the machine looks up
its stored value, which is either computed or delayed. If delayed,
a c1 continuation is pushed and the frozen expression is put in
control. If computed, the value is simply returned. When a value
is returned to a c1 continuation, the store is updated to reflect the
computed value. When a value is returned to a c2 continuation, its
body is put in control and the formal parameter is bound to the
address of the argument.
We now refactor the machine to use store-allocated continuations; storable values are extended to include continuations:
Ï‚âˆˆÎ£
= Exp Ã— Env Ã— Store Ã— Addr
s âˆˆ Storable ::= d(e, Ï) | c(v, Ï) | Îº
Îº âˆˆ Kont
::= mt | c1 (a, a) | c2 (a, a).
It is straightforward to perform a pointer-refinement of the LK machine to store-allocate continuations as done for the CESK machine
in Section 2.3 and observe the lazy variant of Krivineâ€™s machine and
its pointer-refined counterpart (not shown) operate in lock-step:
Lemma 4. eval LK (e) â‰ƒ eval LK ? (e).
After threading time-stamps through the machine as done in
d and alloc
[ analogously to the defiSection 2.4 and defining tick

nitions given in Section 2.5, the pointer-refined machine abstracts
directly to yield the abstract LK? machine in Figure 9.
The abstraction map for this machine is a straightforward structural abstraction similar to that given in Section 2.6 (and hence
omitted). The abstracted machine is sound with respect to the LK?
machine, and therefore the original LK machine.
Theorem 3 (Soundness of the Abstract LK? Machine).
If Ï‚ 7âˆ’â†’LK Ï‚ 0 and Î±(Ï‚) v Ï‚Ë†, then there exists an abstract state Ï‚Ë†0 ,
such that Ï‚Ë† 7âˆ’â†’LK
Ë†0 and Î±(Ï‚ 0 ) v Ï‚Ë†0 .
? Ï‚
[

d
[ Ï‚ , Îº), u = tick(t)
Ï‚Ë† 7âˆ’â†’LK
Ë†0 , where Îº âˆˆ ÏƒÌ‚(a), b = alloc(Ë†
\
0? Ï‚
h(e0 e1 ), Ï, ÏƒÌ‚, ai
h(Î»x.e), Ï, ÏƒÌ‚, ai
if Îº = c2 (e0 , Ï0 , c)

he0 , Ï, ÏƒÌ‚ t [b 7â†’ c2 (e1 , Ï, a)], bi
he, Ï[x 7â†’ b], ÏƒÌ‚ t [b 7â†’ d(e0 , Ï0 )], ci

Figure 11. The abstract thunk postponing LK? machine.

t

Optimizing the machine through specialization: Ager et al. optimize the LK machine by specializing application transitions. When
the operand of an application is a variable, no delayed computation needs to be constructed, thus â€œavoiding the construction of
space-leaky chains of thunks.â€ Likewise, when the operand is a
Î»-abstraction, â€œwe can store the corresponding closure as a computed value rather than as a delayed computation.â€ Both of these
optimizations, which conserve valuable abstract resources, can be
added with no trouble, as shown in Figure 10.
d
[ Ï‚ , Îº), u = tick(t)
Ï‚Ë† 7âˆ’â†’LK
Ë†0 , where Îº âˆˆ ÏƒÌ‚(a), b = alloc(Ë†
? Ï‚
[
h(ex), Ï, ÏƒÌ‚, a, ti
h(ev), Ï, ÏƒÌ‚, a, ti

he, Ï, ÏƒÌ‚ t [b 7â†’ c2 (Ï(x), a)], b, ui
he0 , Ï, ÏƒÌ‚ t [b 7â†’ c(v, Ï), c 7â†’ c2 (b, a)], c, ui
[ Ï‚ , Îº)
where c = alloc(Ë†

Figure 10. The abstract optimized LK? machine.
Varying the machine through postponed thunk creation: Ager
et al. also vary the LK machine by postponing the construction of a
delayed computation from the point at which an application is the
control string to the point at which the operator has been evaluated
and is being applied. The c2 continuation is modified to hold, rather
than the address of a delayed computation, the constituents of the
computation itself:
Îº âˆˆ Kont ::= mt | c1 (a, a) | c2 (e, Ï, a).
The transitions for applications and functions are replaced with
those in Figure 11. This allocates thunks when a function is applied,
rather than when the control string is an application.
As Ager et al. remark, each of these variants gives rise to an
abstract machine. From each of these machines, we are able to
systematically derive their abstractions.

4.

State and control

We have shown that store-allocated continuations make abstract
interpretation of the CESK machine and a lazy variant of Krivineâ€™s
machine straightforward. In this section, we want to show that
the tight correspondence between concrete and abstract persists
after the addition of language features such as conditionals, side
effects, exceptions and continuations. We tackle each feature, and
present the additional machinery required to handle each one. In
most cases, the path from a canonical concrete machine to pointerrefined abstraction of the machine is so simple we only show the
abstracted system. In doing so, we are arguing that this abstract
machine-oriented approach to abstract interpretation represents a
flexible and viable framework for building abstract interpreters.
4.1

Conditionals, mutation, and control

To handle conditionals, we extend the language with a new syntactic form, (if e e e), and introduce a base value #f, representing false. Conditional expressions induce a new continuation form: if (e00 , e01 , Ï, a), which represents the evaluation context

0
d
[ Ï‚ , Îº), u = tick(t)
Ï‚Ë† 7âˆ’â†’CESK
\? Ï‚Ë† , where Îº âˆˆ ÏƒÌ‚(a), b = alloc(Ë†
t

h(if e0 e1 e2 ), Ï, ÏƒÌ‚, a, ti he0 , Ï, ÏƒÌ‚ t [b 7â†’ if (e1 , e2 , Ï, a)], b, ui
h#f, Ï, ÏƒÌ‚, a, ti
he1 , Ï0 , ÏƒÌ‚, c, ui
0
if Îº = if (e0 , e1 , Ï , c)
hv, Ï, ÏƒÌ‚, a, ti
he0 , Ï0 , ÏƒÌ‚, c, ui
if Îº = if (e0 , e1 , Ï0 , c),
and v 6= #f
h(set! x e), Ï, ÏƒÌ‚, a, ti
he, Ï, ÏƒÌ‚ t [b 7â†’ set(Ï(x), a)], b, ui
hv, Ï, ÏƒÌ‚, a, ti
hv 0 , Ï, ÏƒÌ‚ t [a0 7â†’ v], c, ui
0
if Îº = set(a , c)
where v 0 âˆˆ ÏƒÌ‚(a0 )
h(Î»x.e), Ï, ÏƒÌ‚, a, ti
he, Ï[x 7â†’ b], ÏƒÌ‚ t [b 7â†’ c], c, ui
[ Ï‚ , Îº)
if Îº = fn(callcc, Ï0 , c)
where c = alloc(Ë†
hc, Ï, ÏƒÌ‚, a, ti
ha, Ï, ÏƒÌ‚, c, ui
if Îº = fn(callcc, Ï0 , a0 )
hv, Ï, ÏƒÌ‚, a, ti
hv, Ï, ÏƒÌ‚, c, ui
if Îº = fn(c, Ï0 , a0 )
Figure 12. The abstract extended CESK? machine.
E[(if [ ] e0 e1 )] where Ï closes e00 to represent e0 , Ï closes e01 to
represent e1 , and a is the address of the representation of E.
Side effects are fully amenable to our approach; we introduce
Schemeâ€™s set! for mutating variables using the (set! x e) syntax.
The set! form evaluates its subexpression e and assigns the value
to the variable x. Although set! expressions are evaluated for
effect, we follow Felleisen et al. and specify set! expressions
evaluate to the value of x before it was mutated [11, page 166]. The
evaluation context E[(set! x [ ])] is represented by set(a0 , a1 ),
where a0 is the address of xâ€™s value and a1 is the address of the
representation of E.
First-class control is introduced by adding a new base value
callcc which reifies the continuation as a new kind of applicable
value. Denoted values are extended to include representations of
continuations. Since continuations are store-allocated, we choose to
represent them by address. When an address is applied, it represents
the application of a continuation (reified via callcc) to a value.
The continuation at that point is discarded and the applied address
is installed as the continuation.
The resulting grammar is:
e âˆˆ Exp ::= . . . | (if e e e) | (set! x e)
Îº âˆˆ Kont ::= . . . | if (e, e, Ï, a) | set(a, a)
v âˆˆ Val ::= . . . | #f | callcc | a.
We show only the abstract transitions, which result from storeallocating continuations, time-stamping, and abstracting the concrete transitions for conditionals, mutation, and control. The first
three machine transitions deal with conditionals; here we follow
the Scheme tradition of considering all non-false values as true.
The fourth and fifth transitions deal with mutation.

Ï‚ 7âˆ’â†’CESHK Ï‚ 0

Ï‚ 7âˆ’â†’CESHK ? Ï‚ 0 , where Î· = Ïƒ(h), Îº = Ïƒ(a), b âˆˆ
/ dom(Ïƒ)

hv, Ï, Ïƒ, hn(v 0 , Ï0 , Îº, Î·), mti
hv, Ï, Ïƒ, Î·, Îºi
h(throw v), Ï, Ïƒ, hn((Î»x.e), Ï0 , Îº0 , Î·), Îºi
he, Ï0 [x 7â†’ a], Ïƒ[a 7â†’ (v, Ï)], Î·, Îº0 i
where a âˆˆ
/ dom(Ïƒ)
h(catch e v), Ï, Ïƒ, Î·, Îºi
he, Ï, Ïƒ, hn(v, Ï, Îº, Î·), mti

hv, Ï, Ïƒ, h, ai
hv, Ï, Ïƒ, h0 , a0 i
if Î· = hn(v 0 , Ï0 , a0 , h0 ),
and Îº = mt
h(throw v), Ï, Ïƒ, h, ai
he, Ï0 [x 7â†’ b], Ïƒ[b 7â†’ (v, Ï)], h0 , a0 i
if Î· = hn((Î»x.e), Ï0 , a0 , h0 )
h(catch e v), Ï, Ïƒ, h, ai
he, Ï, Ïƒ[b 7â†’ hn(v, Ï, a, h)], b, amt i

Figure 13. The CESHK machine.
Figure 14. The CESHK? machine.
The remaining three transitions deal with first-class control. In
the first of these, callcc is being applied to a closure value v.
The value v is then â€œcalled with the current continuationâ€, i.e., v
is applied to a value that represents the continuation at this point.
In the second, callcc is being applied to a continuation (address).
When this value is applied to the reified continuation, it aborts the
current computation, installs itself as the current continuation, and
puts the reified continuation â€œin the holeâ€. Finally, in the third,
a continuation is being applied; c gets thrown away, and v gets
plugged into the continuation b.
In all cases, these transitions result from pointer-refinement,
time-stamping, and abstraction of the usual machine transitions.
4.2

Exceptions and handlers

To analyze exceptional control flow, we extend the CESK machine
with a register to hold a stack of exception handlers. This models
a reduction semantics in which we have two additional kinds of
evaluation contexts:
E ::= [ ] | (Ee) | (vE) | (catch E v)
F ::= [ ] | (F e) | (vF )
H ::= [ ] | H[F [(catch H v)]],
0

(catch E[(throw v)] v ) â†’ (v v),

hv, Ï, ÏƒÌ‚, h, a, ti
hv, Ï, ÏƒÌ‚, h0 , a0 , ui
0
0
0
0
if Î· = hn(v , Ï , a , h ),
and Îº = mt
h(throw v), Ï, ÏƒÌ‚, h, a, ti
if Î· = hn((Î»x.e), Ï0 , a0 , h0 )
he, Ï0 [x 7â†’ b], ÏƒÌ‚ t [b 7â†’ (v, Ï)], h0 , a0 , ui
h(catch e v), Ï, ÏƒÌ‚, h, a, ti
he, Ï, ÏƒÌ‚ t [b 7â†’ hn(v, Ï, a, h)], b, amt , ui
Figure 15. The abstract CESHK? machine.
In the pointer-refined machine, the grammar of handler continuations changes to the following:
Î· âˆˆ Handl ::= mt | hn(v, Ï, a, h),

and the additional, context-sensitive, notions of reduction:
0

0
[ Ï‚ , Î·, Îº),
Ï‚Ë† 7âˆ’â†’CESHK
\ ? Ï‚Ë† , where Î· âˆˆ ÏƒÌ‚(h), Îº âˆˆ ÏƒÌ‚(a), b = alloc(Ë†
t
d
u = tick(t)

0

(catch v v ) â†’ v.

H contexts represent a stack of exception handlers, while F contexts represent a â€œlocalâ€ continuation, i.e., the rest of the computation (with respect to the hole) up to an enclosing handler, if any.
E contexts represent the entire rest of the computation, including
handlers.
The language is extended with expressions for raising and
catching exceptions. A new kind of continuation is introduced to
represent a stack of handlers. In each frame of the stack, there is a
procedure for handling an exception and a (handler-free) continuation:
e âˆˆ Exp ::= . . . | (throw v) | (catch e (Î»x.e))
Î· âˆˆ Handl ::= mt | hn(v, Ï, Îº, Î·)
An Î· continuation represents a stack of exception handler contexts,
i.e., hn(v 0 , Ï, Îº, Î·) represents H[F [(catch [ ] v)]], where Î·
represents H, Îº represents F , and Ï closes v 0 to represent v.
The machine includes all of the transitions of the CESK machine extended with a Î· component; these transitions are omitted
for brevity. The additional transitions are given in Figure 13. This
presentation is based on a textbook treatment of exceptions and
handlers [11, page 135].5 The initial configuration is given by:
inj CESHK (e) = he, âˆ…, âˆ…, mt, mti.
5 To be precise, Felleisen et al. present the CHC machine, a substitution

based machine that uses evaluation contexts in place of continuations.
Deriving the CESHK machine from it is an easy exercise.

where h is used to range over addresses pointing to handler continuations. The notation amt means a such that Ïƒ(a) = mt in
concrete case and mt âˆˆ ÏƒÌ‚(a) in the abstract, where the intended
store should be clear from context. The pointer-refined machine is
given in Figure 14.
After threading time-stamps through the machine as done in
Section 2.4, the machine abstracts as usual to obtain the machine
in Figure 15. The only unusual step in the derivation is to observe
that some machine transitions rely on a choice of two continuations
from the store; a handler and a local continuation. Analogously
d and alloc
[ to take two continuation
to Section 2.5, we extend tick
arguments to encode the choice:
d : Î£Ì‚ Ã— Handl Ã— Kont â†’ Time,
tick
[ : Î£Ì‚ Ã— Handl Ã— Kont â†’ Addr .
alloc

5. Abstract garbage collection
Garbage collection determines when a store location has become
unreachable and can be re-allocated. This is significant in the abstract semantics because an address may be allocated to multiple
values due to finiteness of the address space. Without garbage collection, the values allocated to this common address must be joined,
introducing imprecision in the analysis (and inducing further, perhaps spurious, computation). By incorporating garbage collection
in the abstract semantics, the location may be proved to be unreachable and safely overwritten rather than joined, in which case
no imprecision is introduced.
Like the rest of the features addressed in this paper, we can
incorporate abstract garbage collection into our static analyzers

Ï‚ 7âˆ’â†’CESK ? Ï‚ 0
he, Ï, Ïƒ, ai
he, Ï, {hb, Ïƒ(b)i | b âˆˆ L}, ai
if hLLÏƒ (e, Ï) âˆª LLÏƒ (Ïƒ(a)), {a}, Ïƒi 7âˆ’â†’
â†’GC hâˆ…, L, Ïƒi
Figure 16. The GC transition for the CESK? machine.
by a straightforward pointer-refinement of textbook accounts of
concrete garbage collection, followed by a finite store abstraction.
Concrete garbage collection is defined in terms of a GC machine
that computes the reachable addresses in a store [11, page 172]:
hG, B, Ïƒi 7âˆ’â†’GC h(G âˆª LLÏƒ (Ïƒ(a)) \ (B âˆª {a})), B âˆª {a}, Ïƒi
if a âˆˆ G.
This machine iterates over a set of reachable but unvisited â€œgreyâ€
locations G. On each iteration, an element is removed and added
to the set of reachable and visited â€œblackâ€ locations B. Any newly
reachable and unvisited locations, as determined by the â€œlive locationsâ€ function LLÏƒ , are added to the grey set. When there are no
grey locations, the black set contains all reachable locations. Everything else is garbage.
The live locations function computes a set of locations which
may be used in the store. Its definition will vary based on the particular machine being garbage collected, but the definition appropriate
for the CESK? machine of Section 2.3 is
LLÏƒ (e) = âˆ…
LLÏƒ (e, Ï) = LLÏƒ (Ï|fv(e))
LLÏƒ (Ï) = rng(Ï)
LLÏƒ (mt) = âˆ…
LLÏƒ (fn(v, Ï, a)) = {a} âˆª LLÏƒ (v, Ï) âˆª LLÏƒ (Ïƒ(a))
LLÏƒ (ar(e, Ï, a)) = {a} âˆª LLÏƒ (e, Ï) âˆª LLÏƒ (Ïƒ(a)).
We write Ï|fv(e) to mean Ï restricted to the domain of free variables in e. We assume the least-fixed-point solution in the calculation of the function LL in cases where it recurs on itself.
The pointer-refinement of the machine requires parameterizing
the LL function with a store used to resolve pointers to continuations. A nice consequence of this parameterization is that we can
re-use LL for abstract garbage collection by supplying it an abstract store for the parameter. Doing so only necessitates extending
LL to the case of sets of storable values:
[
LLÏƒ (S) =
LLÏƒ (s)
sâˆˆS
?

The CESK machine incorporates garbage collection by a transition rule that invokes the GC machine as a subroutine to remove
garbage from the store (Figure 16). The garbage collection transition introduces non-determinism to the CESK? machine because
it applies to any machine state and thus overlaps with the existing
transition rules. The non-determinism is interpreted as leaving the
choice of when to collect garbage up to the machine.
The abstract CESK? incorporates garbage collection by the
concrete garbage collection transition, i.e., we re-use the definition
in Figure 16 with an abstract store, ÏƒÌ‚, in place of the concrete
one. Consequently, it is easy to verify abstract garbage collection
approximates its concrete counterpart.
The CESK? machine may collect garbage at any point in the
computation, thus an abstract interpretation must soundly approximate all possible choices of when to trigger a collection, which
the abstract CESK? machine does correctly. This may be a useful
analysis of garbage collection, however it fails to be a useful analysis with garbage collection: for soundness, the abstracted machine

must consider the case in which garbage is never collected, implying no storage is reclaimed to improve precision.
However, we can leverage abstract garbage collection to reduce
the state-space explored during analysis and to improve precision
and analysis time. This is achieved (again) by considering properties of the concrete machine, which abstract directly; in this case,
we want the concrete machine to deterministically collect garbage.
Determinism of the CESK? machine is restored by defining the
transition relation as a non-GC transition (Figure 3) followed by the
GC transition (Figure 16). This state-space of this concrete machine
is â€œgarbage freeâ€ and consequently the state-space of the abstracted
machine is â€œabstract garbage free.â€
In the concrete semantics, a nice consequence of this property is
that although continuations are allocated in the store, they are deallocated as soon as they become unreachable, which corresponds to
when they would be popped from the stack in a non-pointer-refined
machine. Thus the concrete machine really manages continuations
like a stack.
Similarly, in the abstract semantics, continuations are deallocated as soon as they become unreachable, which often corresponds
to when they would be popped. We say often, because due to the
finiteness of the store, this correspondence cannot always hold.
However, this approach gives a good finite approximation to infinitary stack analyses that can always match calls and returns.

6.

Abstract stack inspection

In this section, we derive an abstract interpreter for the static analysis of a higher-order language with stack inspection. Following the
outline of Section 2 and 3, we start from the tail-recursive CM machine of Clements and Felleisen [3], perform a pointer refinement
on continuations, then abstract the semantics by a parameterized
bounding of the store.
6.1

The Î»sec -calculus and stack-inspection

The Î»sec -calculus of Pottier, Skalka, and Smith is a call-by-value
Î»-calculus model of higher-order stack inspection [26]. We present
the language as given by Clements and Felleisen [3].
All code is statically annotated with a given set of permissions
R, chosen from a fixed set P. A computation whose source code
was statically annotated with a permission may enable that permission for the dynamic extent of a subcomputation. The subcomputation is privileged so long as it is annotated with the same permission, and every intervening procedure call has likewise been
annotated with the privilege.
e âˆˆ Exp ::= . . . | fail | (grant R e) |
(test R e e) | (frame R e)
A fail expression signals an exception if evaluated; by convention
it is used to signal a stack-inspection failure. A (frame R e) evaluates e as the principal R, representing the permissions conferred
on e given its origin. A (grant R e) expression evaluates as e but
with the permissions extended with R enabled. A (test R e0 e1 )
expression evaluates to e0 if R is enabled and e1 otherwise.
A trusted annotator consumes a program and the set of permissions it will operate under and inserts frame expressions around
each Î»-body and intersects all grant expressions with this set of permissions. We assume all programs have been properly annotated.
Stack inspection can be understood in terms of an OK predicate on an evaluation contexts and permissions. The predicate determines whether the given permissions are enabled for a subexpression in the hole of the context. The OK predicate holds whenever the context can be traversed from the hole outwards and, for
each permission, find an enabling grant context without first finding
a denying frame context.

0
Ï‚Ë† 7âˆ’â†’CM
[? Ï‚Ë†

Ï‚ 7âˆ’â†’CM Ï‚ 0
hfail, Ï, Ïƒ, mtâˆ… i

hfail, Ï, Ïƒ, Îºi
h(frame R e), Ï, Ïƒ, Îºi
h(grant R e), Ï, Ïƒ, Îºi
h(test R e0 e1 ), Ï, Ïƒ, Îºi

he, Ï, Ïƒ, Îº[R 7â†’ deny]i
he, Ï, Ïƒ, Îº[R 7â†’ grant]i
(
he0 , Ï, Ïƒ, Îºi
he1 , Ï, Ïƒ, Îºi

if OK(R, Îº),
otherwise

hfail, Ï, ÏƒÌ‚, ai
h(frame R e), Ï, ÏƒÌ‚, ai
h(grant R e), Ï, ÏƒÌ‚, ai
h(test R e0 e1 ), Ï, ÏƒÌ‚, ai

OK(âˆ…, Îº)
m

OK(R, mt )
ff

OK(R, fnm (v, Ï, Îº))
OK(R, arm (e, Ï, Îº))

âˆ’1

â‡â‡’

(R âˆ© m

â‡â‡’

(R âˆ© mâˆ’1 (deny) = âˆ…) âˆ§
OK(R \ mâˆ’1 (grant), Îº)

(deny) = âˆ…)

The CM machine

The CM (continuation-marks) machine of Clements and Felleisen
is a properly tail-recursive extended CESK machine for interpreting
higher-order languages with stack-inspection [3].
In the CM machine, continuations are annotated with marks [4],
which, for the purposes of stack-inspection, are finite maps from
permissions to {deny, grant}:
Îº

mtm | arm (e, Ï, Îº) | fnm (v, Ï, Îº).

::=

We write Îº[R 7â†’ c] to mean update the marks on Îº to m[R 7â†’ c].
The CM machine is defined in Figure 17 (transitions that are
straightforward adaptations of the corresponding CESK? transitions to incorporate continuation marks are omitted). It relies on
the OK predicate to determine whether the permissions in R are
enabled. The OK predicate performs the traversal of the context
(represented as a continuation) using marks to determine which
permissions have been granted or denied.
The semantics of a program is given by the set of reachable
states from an initial machine configuration:
inj CM (e) = he, âˆ…, [a0 7â†’ mtâˆ… ], a0 i.
6.3

The abstract CM? machine

Store-allocating continuations, time-stamping, and bounding the
store yields the transition system given in Figure 18. The notation
ÏƒÌ‚(a)[R 7â†’ c] is used to mean [R 7â†’ c] should update some
continuation in ÏƒÌ‚(a), i.e.,
ÏƒÌ‚(a)[R 7â†’ c] = ÏƒÌ‚[a 7â†’ ÏƒÌ‚(a) \ {Îº} âˆª {Îº[R 7â†’ c]}],
for some Îº âˆˆ ÏƒÌ‚(a). It is worth noting that continuation marks are
updated, not joined, in the abstract transition system.
[? predicate (Figure 18) approximates the pointer refineThe OK
ment of its concrete counterpart OK, which can be understood as
tracing a path through the store corresponding to traversing the continuation. The abstract predicate holds whenever there exists such a
path in the abstract store that would satisfy the concrete predicate:
Consequently, in analyzing (test R e0 e1 ), e0 is reachable only
when the analysis can prove the OK? predicate holds on some path
through the abstract store.
It is straightforward to define a structural abstraction map and
verify the abstract CM? machine is a sound approximation of its
concrete counterpart:
Theorem 4 (Soundness of the Abstract CM? Machine).
If Ï‚ 7âˆ’â†’CM Ï‚ 0 and Î±(Ï‚) v Ï‚Ë†, then there exists an abstract state Ï‚Ë†0 ,
0
0
0
such that Ï‚Ë† 7âˆ’â†’CM
[? Ï‚Ë† and Î±(Ï‚ ) v Ï‚Ë† .
t

he, Ï, ÏƒÌ‚(a)[R 7â†’ deny], ai
he, Ï, ÏƒÌ‚(a)[R 7â†’ grant], ai
(
he0 , Ï, ÏƒÌ‚, ai
he1 , Ï, ÏƒÌ‚, ai

[? (R, ÏƒÌ‚, a),
if OK
otherwise.

[? (âˆ…, ÏƒÌ‚, a)
OK
[? (R, ÏƒÌ‚, a) â‡â‡’ (R âˆ© mâˆ’1 (deny) = âˆ…)
OK
if ÏƒÌ‚(a) 3 mtm
[? (R, ÏƒÌ‚, a) â‡â‡’ (R âˆ© mâˆ’1 (deny) = âˆ…) âˆ§
OK
[? (R \ mâˆ’1 (grant), ÏƒÌ‚, b)
if ÏƒÌ‚(a) 3 fnm (v, Ï, b)
OK
or ÏƒÌ‚(a) 3 arm (e, Ï, b)

Figure 17. The CM machine and OK predicate.
6.2

hfail, Ï, ÏƒÌ‚, amt i

Figure 18. The abstract CM? machine.

7.

Widening to improve complexity

If implemented naÄ±Ìˆvely, it takes time exponential in the size of the
input program to compute the reachable states of the abstracted
machines. Consider the size of the state-space for the abstract timestamped CESK? machine:
[ Ã— Addr Ã— Time|
|Exp Ã— Env Ã— Store
= |Exp| Ã— |Addr ||Var | Ã— |Storable||Addr | Ã— |Addr | Ã— |Time|.
Without simplifying any further, we clearly have an exponential
number of abstract states.
To reduce complexity, we can employ widening in the form of
Shiversâ€™s single-threaded store [29]. To use a single threaded store,
we have to reconsider the abstract evaluation function itself. Instead
of seeing it as a function that returns the set of reachable states, it
is a function that returns a set of partial states plus a single globally
approximating store, i.e., aval : Exp â†’ System, where:
[
System = P (Exp Ã— Env Ã— Addr Ã— Time) Ã— Store.
We compute this as a fixed point of a monotonic function, f :
f : System â†’ System
f (C, ÏƒÌ‚) = (C 0 , ÏƒÌ‚ 00 ) where
Ë˜
Â¯
Q0 = (c0 , ÏƒÌ‚ 0 ) : c âˆˆ C and (c, ÏƒÌ‚) 7âˆ’â†’ (c0 , ÏƒÌ‚ 0 )
(c0 , ÏƒÌ‚0 ) âˆ¼
= inj (e)
Â¯
Ë˜
C 0 = C âˆª c0 : (c0 , ) âˆˆ Q0 âˆª {c0 }
G
ÏƒÌ‚ 00 = ÏƒÌ‚ t
ÏƒÌ‚ 0 ,
( ,ÏƒÌ‚ 0 )âˆˆQ0

so that aval (e) = lfp(f ). The maximum number of iterations of
the function f times the cost of each iteration bounds the complexity of the analysis.
Polynomial complexity for monovariance: It is straightforward
to compute the cost of a monovariant (in our framework, a â€œ0CFAlikeâ€) analysis with this widening. In a monovariant analysis, environments disappear; a monovariant system-space simplifies to:
System 0
= P (Exp Ã— Lab Ã— Lab âŠ¥ )
addresses

fn conts

ar conts

z
}|
{
z
}|
{ z
}|
{
Ã— ((Var + Lab) â†’ (Exp Ã— Lab) + (Exp Ã— Lab) +Lam).

If ascended monotonically, one could add one new partial state
each time or introduce a new entry into the global store. Thus, the
maximum number of monovariant iterations is:
|Exp| Ã— |Lab|2 + 1
+ |Var + Lab| Ã— (2|Exp Ã— Lab| + |Lam|),
which is cubic in the size of the program.

8.

Related work

The study of abstract machines for the Î»-calculus began with
Landinâ€™s SECD machine [21], the theory of abstract interpretation with the POPL papers of the Cousotsâ€™ [6, 7], and static analysis of the Î»-calculus with Jonesâ€™s coupling of abstract machines
and abstract interpretation [17]. All three have been active areas of research since their inception, but only recently have well
known abstract machines been connected with abstract interpretation by Midtgaard and Jensen [23, 24]. We strengthen the connection by demonstrating a general technique for abstracting abstract
machines.
Abstract interpretation of abstract machines: The approximation of abstract machine states for the analysis of higher-order languages goes back to Jones [17], who argued abstractions of regular
tree automata could solve the problem of recursive structure in environments. We re-invoked that wisdom to eliminate the recursive
structure of continuations by allocating them in the store.
Midtgaard and Jensen present a 0CFA for a CPS Î»-calculus language [23]. The approach is based on Cousot-style calculational abstract interpretation [5], applied to a functional language. Like the
present work, Midtgaard and Jensen start with an â€œoff-the-shelfâ€
abstract machine for the concrete semantics (in this case, the CE
machine of Flanagan, et al. [14]) and employ a reachable-states
model. They then compose well-known Galois connections to reveal a 0CFA with reachability in the style of Ayers [2].6 The CE
machine is not sufficient to interpret direct-style programs, so the
analysis is specialized to programs in continuation-passing style.
Later work by Midtgaard and Jensen went on to present a similar
calculational abstract interpretation treatment of a monomorphic
CFA for an ANF Î»-calculus [24]. The concrete semantics are based
on reachable states of the Ca EK machine [14]. The abstract semantics approximate the control stack component of the machine by its
top element, which is similar to the labeled machine abstraction
given in Section 2.7 when k = 0.
Although our approach is not calculational like Midtgaard and
Jensenâ€™s, it continues in their tradition by applying abstract interpretation to off-the-shelf tail-recursive machines. We extend the
application to direct-style machines for a k-CFA-like abstraction
that handles tail calls, laziness, state, exceptions, first-class continuations, and stack inspection. We have extended return flow analysis to a completely direct style (no ANF or CPS needed) within a
framework that accounts for polyvariance.
Harrison gives an abstract interpretation for a higher-order language with control and state for the purposes of automatic parallelization [15]. Harrison maps Scheme programs into an imperative intermediate language, which is interpreted on a novel abstract
machine. The machine uses a procedure string approach similar to
that given in Section 2.7 in that the store is addressed by procedure strings. Harrisonâ€™s first machine employs higher-order values
to represent functions and continuations and he notes, â€œthe straightforward abstraction of this semantics leads to abstract domains
6 Ayers derived an abstract interpreter by transforming (the representation

of) a denotational continuation semantics of Scheme into a state transition
system (an abstract machine), which he then approximated using Galois
connections [2].

containing higher-order objects (functions) over reflexive domains,
whereas our purpose requires a more concrete compile-time representation of the values assumed by variables. We therefore modify
the semantics such that its abstraction results in domains which are
both finite and non-reflexive.â€ Because of the reflexivity of denotable values, a direct abstraction is not possible, so he performs
closure conversion on the (representation of) the semantic function. Harrison then abstracts the machine by bounding the procedure string space (and hence the store) via an abstraction he calls
stack configurations, which is represented by a finite set of members, each of which describes an infinite set of procedure strings.
To prove that Harrisonâ€™s abstract interpreter is correct he argues
that the machine interpreting the translation of a program in the
intermediate language corresponds to interpreting the program as
written in the standard semanticsâ€”in this case, the denotational
semantics of R3 RS. On the other hand, our approach relies on well
known machines with well known relations to calculi, reduction
semantics, and other machines [10, 8]. These connections, coupled
with the strong similarities between our concrete and abstract machines, result in minimal proof obligations in comparison. Moreover, programs are analyzed in direct-style under our approach.
Abstract interpretation of lazy languages: Jones has analyzed
non-strict functional languages [17, 16], but that work has only focused on the by-name aspect of laziness and does not address memoization as done here. Sestoft examines flow analysis for lazy languages and uses abstract machines to prove soundness [27]. In particular, Sestoft presents a lazy variant of Krivineâ€™s machine similar
to that given in Section 3 and proves analysis is sound with respect
to the machine. Likewise, Sestoft uses Landinâ€™s SECD machine as
the operational basis for proving globalization optimizations correct. Sestoftâ€™s work differs from ours in that analysis is developed
separately from the abstract machines, whereas we derive abstract
interpreters directly from machine definitions. FaxeÌn uses a typebased flow analysis approach to analyzing a functional language
with explicit thunks and evals, which is intended as the intermediate language for a compiler of a lazy language [9]. In contrast, our
approach makes no assumptions about the typing discipline and analyzes source code directly.
Realistic language features and garbage collection: Static analyzers typically hemorrhage precision in the presence of exceptions and first-class continuations: they jump to the top of the lattice
of approximation when these features are encountered. Conversion
to continuation- and exception-passing style can handle these features without forcing a dramatic ascent of the lattice of approximation [29]. The cost of this conversion, however, is lost knowledgeâ€”
both approaches obscure static knowledge of stack structure, by
desugaring it into syntax.
Might and Shivers introduced the idea of using abstract garbage
collection to improve precision and efficiency in flow analysis [25].
They develop a garbage collecting abstract machine for a CPS language and prove it correct. We extend abstract garbage collection
to direct-style languages interpreted on the CESK machine.
Static stack inspection: Most work on the static verification of
stack inspection has focused on type-based approaches. Skalka
and Smith present a type system for static enforcement of stackinspection [30]. Pottier et al. present type systems for enforcing
stack-inspection developed via a static correspondence to the dynamic notion of security-passing style [26]. Skalka et al. present
type and effect systems that use linear temporal logic to express
regular properties of program traces and show how to statically enforce both stack- and history-based security mechanisms [31]. Our
approach, in contrast, is not typed-based and focuses only on stackinspection, although it seems plausible the approach of Section 6
extends to the more general history-based mechanisms.

9.

Conclusions and perspective

We have demonstrated the utility of store-allocated continuations
by deriving novel abstract interpretations of the CEK, a lazy variant of Krivineâ€™s, and the stack-inspecting CM machines. These
abstract interpreters are obtained by a straightforward pointer refinement and structural abstraction that bounds the address space,
making the abstract semantics safe and computable. Our technique
allows concrete implementation technology to be mapped straightforwardly into that of static analysis, which we demonstrated by incorporating abstract garbage collection and optimizations to avoid
abstract space leaks, both of which are based on existing accounts
of concrete GC and space efficiency. Moreover, the abstract interpreters properly model tail-calls by virtue of their concrete counterparts being properly tail-call optimizing. Finally, our technique
uniformly scales up to richer language features. We have supported
this by extending the abstract CESK machine to analyze conditionals, first-class control, exception handling, and state. We speculate
that store-allocating bindings and continuations is sufficient for a
straightforward abstraction of most existing machines.
Acknowledgments: We thank Matthias Felleisen, Jan Midtgaard,
and Sam Tobin-Hochstadt for discussions and suggestions. We also
thank the anonymous reviewers for their close reading and helpful
critiques; their comments have improved this paper.

References
[1] Mads S. Ager, Olivier Danvy, and Jan Midtgaard. A functional
correspondence between call-by-need evaluators and lazy abstract
machines. Information Processing Letters, 90(5):223â€“232, June
2004.
[2] Andrew E. Ayers. Abstract analysis and optimization of Scheme. PhD
thesis, Massachusetts Institute of Technology, 1993.
[3] John Clements and Matthias Felleisen. A tail-recursive machine with
stack inspection. ACM Trans. Program. Lang. Syst., 26(6):1029â€“
1052, November 2004.
[4] John Clements, Matthew Flatt, and Matthias Felleisen. Modeling an
algebraic stepper. In ESOP â€™01: Proceedings of the 10th European
Symposium on Programming Languages and Systems, pages 320â€“
334, 2001.
[5] Patrick Cousot. The calculational design of a generic abstract
interpreter. In M. Broy and R. SteinbruÌˆggen, editors, Calculational
System Design. 1999.
[6] Patrick Cousot and Radhia Cousot. Abstract interpretation: A unified
lattice model for static analysis of programs by construction or
approximation of fixpoints. In Conference Record of the Fourth
ACM Symposium on Principles of Programming Languages, pages
238â€“252, 1977.
[7] Patrick Cousot and Radhia Cousot. Systematic design of program
analysis frameworks. In POPL â€™79: Proceedings of the 6th ACM
SIGACT-SIGPLAN Symposium on Principles of Programming
Languages, pages 269â€“282, 1979.
[8] Olivier Danvy. An Analytical Approach to Program as Data Objects.
DSc thesis, Department of Computer Science, Aarhus University,
October 2006.
[9] Karl FaxeÌn. Optimizing lazy functional programs using flow
inference. In Static Analysis, pages 136â€“153. 1995.
[10] Matthias Felleisen. The Calculi of Lambda-v-CS Conversion: A
Syntactic Theory of Control and State in Imperative Higher-Order
Programming Languages. PhD thesis, Indiana University, 1987.
[11] Matthias Felleisen, Robert B. Findler, and Matthew Flatt. Semantics
Engineering with PLT Redex. August 2009.
[12] Matthias Felleisen and Daniel P. Friedman. Control operators, the
SECD-machine, and the lambda-calculus. In 3rd Working Conference
on the Formal Description of Programming Concepts, August 1986.

[13] Mattias Felleisen and D. P. Friedman. A calculus for assignments
in higher-order languages. In POPL â€™87: Proceedings of the 14th
ACM SIGACT-SIGPLAN Symposium on Principles of Programming
Languages, pages 314+, 1987.
[14] Cormac Flanagan, Amr Sabry, Bruce F. Duba, and Matthias Felleisen.
The essence of compiling with continuations. In PLDI â€™93:
Proceedings of the ACM SIGPLAN 1993 Conference on Programming
Language Design and Implementation, pages 237â€“247, June 1993.
[15] Williams L. Harrison. The interprocedural analysis and automatic
parallelization of scheme programs. LISP and Symbolic Computation,
2(3):179â€“396, October 1989.
[16] N. Jones and N. Andersen. Flow analysis of lazy higher-order
functional programs. Theoretical Computer Science, 375(1-3):120â€“
136, May 2007.
[17] Neil D. Jones. Flow analysis of lambda expressions (preliminary
version). In Proceedings of the 8th Colloquium on Automata,
Languages and Programming, pages 114â€“128, 1981.
[18] Neil D. Jones and Steven S. Muchnick. A flexible approach to
interprocedural data flow analysis and programs with recursive data
structures. In POPL â€™82: Proceedings of the 9th ACM SIGPLANSIGACT Symposium on Principles of Programming Languages, pages
66â€“74, 1982.
[19] Jean-Louis Krivine. Un interpreÌteur du lambda-calcul. 1985.
[20] Jean-Louis Krivine. A call-by-name lambda-calculus machine.
Higher-Order and Symbolic Computation, 20(3):199â€“207, September
2007.
[21] Peter J. Landin. The mechanical evaluation of expressions. The
Computer Journal, 6(4):308â€“320, 1964.
[22] Jan Midtgaard. Control-flow analysis of functional programs. Technical Report BRICS RS-07-18, DAIMI, Department of Computer
Science, University of Aarhus, December 2007. To appear in revised
form in ACM Computing Surveys.
[23] Jan Midtgaard and Thomas Jensen. A calculational approach to
control-flow analysis by abstract interpretation. In MarÄ±Ìa Alpuente
and GermaÌn Vidal, editors, SAS, volume 5079 of Lecture Notes in
Computer Science, pages 347â€“362, 2008.
[24] Jan Midtgaard and Thomas P. Jensen. Control-flow analysis of
function calls and returns by abstract interpretation. In ICFP â€™09:
Proceedings of the 14th ACM SIGPLAN International Conference on
Functional Programming, pages 287â€“298, 2009.
[25] Matthew Might and Olin Shivers. Improving flow analyses via Î“CFA:
Abstract garbage collection and counting. In ICFP â€™06: Proceedings
of the Eleventh ACM SIGPLAN International Conference on
Functional Programming, pages 13â€“25, 2006.
[26] FrancÌ§ois Pottier, Christian Skalka, and Scott Smith. A systematic
approach to static access control. ACM Trans. Program. Lang. Syst.,
27(2):344â€“382, March 2005.
[27] Peter Sestoft. Analysis and efficient implementation of functional
programs. PhD thesis, University of Copenhagen, October 1991.
[28] Zhong Shao and Andrew W. Appel. Space-efficient closure
representations. In LFP â€™94: Proceedings of the 1994 ACM
Conference on LISP and Functional Programming, pages 150â€“161,
1994.
[29] Olin G. Shivers. Control-Flow Analysis of Higher-Order Languages.
PhD thesis, Carnegie Mellon University, 1991.
[30] Christian Skalka and Scott Smith. Static enforcement of security
with types. In ICFP â€™00: Proceedings of the fifth ACM SIGPLAN
International Conference on Functional Programming, pages 34â€“45,
September 2000.
[31] Christian Skalka, Scott Smith, and David Van Horn. Types and
trace effects of higher order programs. Journal of Functional
Programming, 18(02):179â€“249, 2008.

